CreateNotePage.tsx:

import ReactDOM from 'react-dom';
import { FC, useState, useCallback, useEffect, useRef } from 'react';
import { useNavigate } from 'react-router-dom';
import { Page } from '../../components/Page';
import { EditorContent, useEditor } from '@tiptap/react';
import StarterKit from '@tiptap/starter-kit';
import Placeholder from '@tiptap/extension-placeholder';
import CodeBlock from '@tiptap/extension-code-block';
import styles from './CreateNotePage.module.scss';
import Code from '@tiptap/extension-code';
import { NoteHeader } from './components/NoteHeader/NoteHeader';
import { Toolbar } from './components/Toolbar/Toolbar';
import { AIModal } from './components/AIModal/AIModal';
import { isMobile } from 'react-device-detect';
import axios from 'axios';


interface HistoryEntry {
  type: 'title' | 'content';
  content: string;
}

interface SpeechRecognitionError extends Event {
  error: string;
}

export const CreateNotePage: FC = () => {
  const navigate = useNavigate();
  const [title, setTitle] = useState('');
  const [content, setContent] = useState('');
  const [isEditing, setIsEditing] = useState(true);
  const [history, setHistory] = useState<HistoryEntry[]>([]);
  const [redoStack, setRedoStack] = useState<HistoryEntry[]>([]);
  const [keyboardHeight, setKeyboardHeight] = useState(0);
  const [canSave, setCanSave] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [audioContext, setAudioContext] = useState<AudioContext | null>(null);
  const [analyser, setAnalyser] = useState<AnalyserNode | null>(null);
  const [isModalOpen, setIsModalOpen] = useState(false);
  const [aiInput, setAiInput] = useState('');
  const [aiGenerating, setAiGenerating] = useState(false);
  const [generatedContent, setGeneratedContent] = useState('');
  
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  

  const speechLanguage = (localStorage.getItem('speechLanguage') || 'en-US').split('-')[0].toUpperCase();

  const titleEditor = useEditor({
    extensions: [StarterKit, Placeholder.configure({
       placeholder: 'Title',
       emptyNodeClass:
       'first:before:text-gray-400 first:before:float-left first:before:content-[attr(data-placeholder)] first:before:h-0', })],
    content: title,
    editable: isEditing,
    onUpdate: ({ editor }) => {
      const text = editor.getText();
      ReactDOM.unstable_batchedUpdates(() => {
        setHistory((prev) => [...prev, { type: 'title', content: title }]);
        setTitle(text);
        setRedoStack([]);
      });
    },
  });

  const contentEditor = useEditor({
    extensions: [
      StarterKit,
      Placeholder.configure({
      placeholder: 'Type your content here...',
      emptyNodeClass:
       'first:before:text-gray-400 first:before:float-left first:before:content-[attr(data-placeholder)] first:before:h-0',
     }),
      Code,
      CodeBlock.configure({ HTMLAttributes: { class: 'code-block' } }),
    ],
    content: content,
    editable: isEditing,
    onUpdate: ({ editor }) => {
      const htmlContent = editor.getHTML();
      ReactDOM.unstable_batchedUpdates(() => {
        setHistory((prev) => [...prev, { type: 'content', content }]);
        setContent(htmlContent);
        setRedoStack([]);
      });
    },
  });

  useEffect(() => {
    setCanSave(title.trim().length > 0 && content.trim().length > 0);
  }, [title, content]);

  useEffect(() => {
    if (titleEditor) {
      titleEditor.commands.focus('end');
    }

    const handleResize = () => {
      if (isMobile) {
        const newKeyboardHeight = window.innerHeight - document.documentElement.clientHeight;
        setKeyboardHeight(newKeyboardHeight > 0 ? newKeyboardHeight : 0);
      } else {
        setKeyboardHeight(0);
      }
    };

    window.addEventListener('resize', handleResize);
    return () => window.removeEventListener('resize', handleResize);
  }, [titleEditor]);

  const handleUndo = useCallback(() => {
    if (history.length === 0) return;

    const lastChange = history.pop();
    setRedoStack((prev) => [lastChange!, ...prev]);

    if (lastChange?.type === 'title') {
      setTitle(lastChange.content);
      titleEditor?.commands.setContent(lastChange.content);
    } else if (lastChange?.type === 'content') {
      setContent(lastChange.content);
      contentEditor?.commands.setContent(lastChange.content);
    }

    setHistory([...history]);
  }, [history, titleEditor, contentEditor]);

  const handleRedo = useCallback(() => {
    if (redoStack.length === 0) return;

    const nextChange = redoStack.shift();
    setHistory((prev) => [...prev, nextChange!]);

    if (nextChange?.type === 'title') {
      setTitle(nextChange.content);
      titleEditor?.commands.setContent(nextChange.content);
    } else if (nextChange?.type === 'content') {
      setContent(nextChange.content);
      contentEditor?.commands.setContent(nextChange.content);
    }

    setRedoStack([...redoStack]);
  }, [redoStack, titleEditor, contentEditor]);

  const handleSaveClick = () => {
    const newId = Date.now().toString();
    const notes = JSON.parse(localStorage.getItem('notes') || '{}');
    notes[newId] = { title, content };
    localStorage.setItem('notes', JSON.stringify(notes));
    navigate('/index');
  };

  const handleCancelClick = () => {
    navigate('/index');
  };

  const handleSpeechRecognition = () => {
    if (!recognitionRef.current) {
      recognitionRef.current = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      recognitionRef.current.lang = speechLanguage;
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = true;

      recognitionRef.current.onstart = () => {
        setIsListening(true);
      };

      recognitionRef.current.onresult = (event: SpeechRecognitionEvent) => {
        const transcriptArray = Array.from(event.results)
          .map((result) => result[0].transcript)
          .join(' ');

        const isFinal = event.results[event.results.length - 1].isFinal;
        const processedText = transcriptArray
          .replace(/\bnew line\b/gi, '\n')
          .replace(/\bcomma\b/gi, ',')
          .replace(/\bperiod\b/gi, '.')
          .replace(/\bdelete\b/gi, () => {
            setContent((prevContent) => prevContent.slice(0, -1));
            return '';
          });

          const newContent = `${processedText} `;

          requestAnimationFrame(() => {
            contentEditor?.commands.setContent(
              `<motion.div
                key={Date.now()}
                initial={{ opacity: 0, y: 10 }}
                animate={{ opacity: 1, y: 0 }}
                exit={{ opacity: 0, y: -10 }}
                transition={{ duration: 0.3 }}
              >
                ${newContent}
              </motion.div>`,
              isFinal
            );
          });
      };

      recognitionRef.current.onerror = (event: SpeechRecognitionError) => {
        console.error(`Error: ${event.error}`);
      };

      recognitionRef.current.onend = () => {
        setIsListening(false);
        if (isListening) recognitionRef.current?.start();
      };
    }

    recognitionRef.current.start();
  };

  const handleStopListening = () => {
    recognitionRef.current?.stop();
    setIsListening(false);
  };

  useEffect(() => {
    if (!isListening || audioContext) return;
  
    const context = new AudioContext();
    const analyserNode = context.createAnalyser();
    analyserNode.fftSize = 256;
  
    navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
      const source = context.createMediaStreamSource(stream);
      source.connect(analyserNode);
      setAudioContext(context);
      setAnalyser(analyserNode);
    });
  
    return () => {
      context?.close();
      setAudioContext(null);
      setAnalyser(null);
    };
  }, [isListening]);

  useEffect(() => {
    if (generatedContent && generatedContent.length <= 100000) {
      contentEditor?.commands.setContent(generatedContent);
    }
  }, [generatedContent]);

  
  

  const openModal = () => setIsModalOpen(true);
  const closeModal = () => setIsModalOpen(false);
  
  const generateAIContent = async () => {
    if (!aiInput.trim()) return;
    setAiGenerating(true);
  
    try {
      const response = await axios.post(
        'https://api.cohere.ai/generate',
        {
          model: 'command-xlarge-nightly',
          prompt: aiInput,
          max_tokens: 500,
          temperature: 0.7,
        },
        {
          headers: {
            Authorization: `Bearer fXzcYyUOXqbUqzarYPhzFp2C21qGhj1V3orIzslW`,
            'Content-Type': 'application/json',
          }
        }
      );
  
      let generatedText = response.data.text.trim(); 
      generatedText = generatedText.replace(/\n\n/g, '<p></p>');
  
      let animatedHTML = `
        <div class="ai-content" style="opacity: 0; transform: translateY(20px); transition: all 0.5s ease-out;">
          ${generatedText}
        </div>
      `;
  
      if (animatedHTML.length > 30000) {
        animatedHTML = `${animatedHTML.slice(0, 30000)}...`;
      }
  
      setGeneratedContent((prevContent) => `${prevContent}\n\n${animatedHTML}`);
    } catch (error) {
      console.error('Error generating AI content:', error);
    } finally {
      setAiGenerating(false);
      closeModal();
    }
  };
  

  useEffect(() => {
    if (generatedContent) {
      const safeContent = `${content}\n\n${generatedContent}`;
      if (safeContent.length > 30000) {
        console.warn('Content length exceeds maximum allowed size.');
      } else {
        setContent(safeContent);
        contentEditor?.commands.setContent(safeContent); 
      }
    }
  }, [generatedContent, contentEditor]);
  
  return (
    <Page back={true}>
      <NoteHeader
        handleUndo={handleUndo}
        handleRedo={handleRedo}
        handleSpeechRecognition={handleSpeechRecognition}
        handleStopListening={handleStopListening}
        handleCancelClick={handleCancelClick}
        handleSaveClick={handleSaveClick}
        openModal={openModal}
        isListening={isListening}
        historyLength={history.length}
        redoStackLength={redoStack.length}
        canSave={canSave}
        speechLanguage={speechLanguage}
        audioContext={audioContext}
        analyser={analyser}
      />
      <div className={styles.scrollContainer}>
        <div onClick={() => setIsEditing(true)} className={styles.titleEditorContainer}>
          <EditorContent editor={titleEditor} className={styles.titleEditor} />
        </div>
        <div onClick={() => setIsEditing(true)} className={styles.editorContainer}>
          <EditorContent editor={contentEditor} className={styles.editorContent} />
        </div>
      </div>
      {isEditing && (
        <Toolbar
          contentEditor={contentEditor}
          isMobile={isMobile}
          keyboardHeight={keyboardHeight}
         />
      )}
      <AIModal
        isOpen={isModalOpen}
        onClose={() => setIsModalOpen(false)}
        onGenerate={generateAIContent}
        aiInput={aiInput}
        setAiInput={setAiInput}
        aiGenerating={aiGenerating}
      />
    </Page>
  );
};

NoteHeader.tsx:

import { FC } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { Undo2, Redo2, Mic } from 'lucide-react';
import { useTranslation } from 'react-i18next';
import SoundVisualizer from '@/components/SoundVisualizer';
import styles from './NoteHeader.module.scss';

interface NoteHeaderProps {
  handleUndo: () => void;
  handleRedo: () => void;
  handleSpeechRecognition: () => void;
  handleStopListening: () => void;
  handleCancelClick: () => void;
  handleSaveClick: () => void;
  openModal: () => void;
  isListening: boolean;
  historyLength: number;
  redoStackLength: number;
  canSave: boolean;
  speechLanguage: string;
  audioContext: AudioContext | null;
  analyser: AnalyserNode | null;
}

export const NoteHeader: FC<NoteHeaderProps> = ({
  handleUndo,
  handleRedo,
  handleSpeechRecognition,
  handleStopListening,
  handleCancelClick,
  handleSaveClick,
  openModal,
  isListening,
  historyLength,
  redoStackLength,
  canSave,
  audioContext,
  analyser,
}) => {
  const { t } = useTranslation();

  return (
    <header className={styles.noteHeader}>
      <AnimatePresence mode="wait">
        <motion.div
          key="toolbar"
          initial={{ opacity: 0, x: 20 }}
          animate={{ opacity: 1, x: 0 }}
          exit={{ opacity: 0, x: -20 }}
          transition={{ duration: 0.2 }}
          className={styles.noteHeaderTools}
        >
          <div className={styles.noteHeaderToolRow}>
            <button onClick={handleUndo} className={styles.undoButton} disabled={historyLength === 0}>
              <Undo2 />
            </button>
            <button onClick={handleRedo} className={styles.redoButton} disabled={redoStackLength === 0}>
              <Redo2 />
            </button>
            <button onClick={openModal} className={styles.aiButton}>
              AI
            </button>
            <button
              onClick={isListening ? handleStopListening : handleSpeechRecognition}
              className={`${styles.microphoneButton} ${isListening ? styles.active : ''}`}
              aria-label={t('Start voice input')}
            >
              <AnimatePresence mode="wait">
                {isListening ? (
                  <motion.div
                    key="visualizer"
                    className={styles.visualizerContainer}
                    initial={{ opacity: 0, scale: 0 }}
                    animate={{ opacity: 1, scale: 1 }}
                    exit={{ opacity: 0, scale: 0 }}
                    transition={{
                      type: 'spring',
                      stiffness: 500,
                      damping: 30,
                    }}
                  >
                    <SoundVisualizer audioContext={audioContext} analyser={analyser} isActive={isListening} />
                  </motion.div>
                ) : (
                  <motion.div
                    key="micIcon"
                    className={styles.micIcon}
                    initial={{ opacity: 0, scale: 0 }}
                    animate={{ opacity: 1, scale: 1 }}
                    exit={{ opacity: 0, scale: 0 }}
                    transition={{
                      type: 'spring',
                      stiffness: 500,
                      damping: 30,
                    }}
                  >
                    <Mic />
                  </motion.div>
                )}
              </AnimatePresence>
            </button>
          </div>
          <div className={styles.noteHeaderToolRow}>
            <button onClick={handleCancelClick} className={styles.cancelButton}>
              {t('Cancel')}
            </button>
            <button onClick={handleSaveClick} className={styles.saveButton} disabled={!canSave}>
              {t('Save')}
            </button>
          </div>
        </motion.div>
      </AnimatePresence>
    </header>
  );
};

Toolbar.tsx:

import { FC } from 'react';
import { Editor } from '@tiptap/react';
import styles from './Toolbar.module.scss';
import { motion } from 'framer-motion';

interface ToolbarProps {
  contentEditor: Editor | null;
  isMobile: boolean;
  keyboardHeight: number;
}

export const Toolbar: FC<ToolbarProps> = ({ contentEditor, isMobile, keyboardHeight }) => {
  return (
    <motion.div
     className={styles.toolbar}
     initial={{ opacity: 0, y: 20 }}
     animate={{ opacity: 1, y: 0 }}
     exit={{ opacity: 0, y: 20 }}
     transition={{ duration: 0.2, ease: "easeInOut" }}
     style={{
        bottom: isMobile ? `${keyboardHeight}px` : '20px',
     }}
    >
      <button
        onClick={() => contentEditor?.chain().focus().toggleBold().run()}
        className={contentEditor?.isActive('bold') ? styles.activeButton : ''}
      >
        Bold
      </button>
      <button
        onClick={() => contentEditor?.chain().focus().toggleItalic().run()}
        className={contentEditor?.isActive('italic') ? styles.activeButton : ''}
      >
        Italic
      </button>
      <button
        onClick={() => contentEditor?.chain().focus().toggleStrike().run()}
        className={contentEditor?.isActive('strike') ? styles.activeButton : ''}
      >
        Strike
      </button>
      <button
        onClick={() => contentEditor?.chain().focus().toggleCode().run()}
        className={contentEditor?.isActive('code') ? styles.activeButton : ''}
      >
        Code
      </button>
      <button
        onClick={() => contentEditor?.chain().focus().toggleCodeBlock().run()}
        className={contentEditor?.isActive('codeBlock') ? styles.activeButton : ''}
      >
        Code Block
      </button>
    </motion.div>
  );
}

AIModal.tsx:

import { FC } from 'react';
import { useTranslation } from 'react-i18next';
import Modal from '@/components/Modal/Modal';
import styles from './AIModal.module.scss';

interface AIModalProps {
  isOpen: boolean;
  onClose: () => void;
  onGenerate: () => void;
  aiInput: string;
  setAiInput: (value: string) => void;
  aiGenerating: boolean;
}

export const AIModal: FC<AIModalProps> = ({
  isOpen,
  onClose,
  onGenerate,
  aiInput,
  setAiInput,
  aiGenerating,
}) => {
  const { t } = useTranslation();

  return (
    <Modal isOpen={isOpen} onClose={onClose}>
      <h2 className={styles.generateContent}>{t('Generate AI Content')}</h2>
      <textarea
        value={aiInput}
        onChange={(e) => setAiInput(e.target.value)}
        placeholder={t('Type your topic or question...')}
        className={styles.aiInput}
      />
      <div className={styles.modalActions}>
        <button onClick={onClose} className={styles.cancelButton}>
          {t('Cancel')}
        </button>
        <button
          onClick={onGenerate}
          disabled={aiGenerating}
          className={styles.generateButton}
        >
          {aiGenerating ? t('Generating...') : t('Generate')}
        </button>
      </div>
    </Modal>
  );
};